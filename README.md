# DeepSeek R1 Model Fine-Tuning

## Model Used
*unsloth/DeepSeek-R1-Distill-Llama-8B*

## Framework Used for Fine-Tuning
*Unsloth*

This framework allows for fine-tuning with minimal device configuration.

## Fine-Tuning Techniques

Applied `LoRA (Low-Rank Adaptation)` techniques to enhance fine-tuning performance.

Utilized the `Transformers` library to update the optimizer settings, as well as the number of epochs and batch sizes for training the model.


# DataSource
[MedQA](https://drive.google.com/file/d/1ImYUSLk9JbgHXOemfvyiDiirluZHPeQw/view)
